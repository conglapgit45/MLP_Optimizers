{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsizk+a6D5MJY1Rct17p6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conglapgit45/MLP_Optimizers/blob/main/Optimizations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVO8d9cazWK5"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def df_w(W):\n",
        "    dw1 = 0.2 * W[0]\n",
        "    dw2 = 4 * W[1]\n",
        "    dW = np.array([dw1, dw2])\n",
        "    return dW"
      ],
      "metadata": {
        "id": "eB3YSGPU0RY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(W, dW, lr):\n",
        "    W = W - lr * dW\n",
        "    return W"
      ],
      "metadata": {
        "id": "qG4f7VUZ2AWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_p1(optimizer, lr, epochs):\n",
        "    # initial point\n",
        "    W = np.array([-5, -2], dtype=np.float32)\n",
        "    # list of results\n",
        "    results = [W]\n",
        "    for epoch in range(epochs):\n",
        "        dW = df_w(W)\n",
        "        W = optimizer(W, dW, lr)\n",
        "        results.append(W)\n",
        "    return results"
      ],
      "metadata": {
        "id": "JZiWG_a43G-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_p1(sgd, 0.4, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGXVXzyk40XB",
        "outputId": "b9c164cf-4e1f-454f-f2fd-1e5533182ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([-5., -2.], dtype=float32), array([-4.6,  1.2]), array([-4.232, -0.72 ]), array([-3.89344,  0.432  ]), array([-3.5819648, -0.2592   ]), array([-3.29540762,  0.15552   ]), array([-3.03177501, -0.093312  ]), array([-2.78923301,  0.0559872 ]), array([-2.56609437, -0.03359232]), array([-2.36080682,  0.02015539]), array([-2.17194227, -0.01209324]), array([-1.99818689,  0.00725594]), array([-1.83833194, -0.00435356]), array([-1.69126538,  0.00261214]), array([-1.55596415, -0.00156728]), array([-1.43148702e+00,  9.40369969e-04]), array([-1.31696806e+00, -5.64221981e-04]), array([-1.21161061e+00,  3.38533189e-04]), array([-1.11468176e+00, -2.03119913e-04]), array([-1.02550722e+00,  1.21871948e-04]), array([-9.43466646e-01, -7.31231688e-05]), array([-8.67989314e-01,  4.38739013e-05]), array([-7.98550169e-01, -2.63243408e-05]), array([-7.34666155e-01,  1.57946045e-05]), array([-6.75892863e-01, -9.47676268e-06]), array([-6.21821434e-01,  5.68605761e-06]), array([-5.72075719e-01, -3.41163456e-06]), array([-5.26309662e-01,  2.04698074e-06]), array([-4.84204889e-01, -1.22818844e-06]), array([-4.45468498e-01,  7.36913066e-07]), array([-4.09831018e-01, -4.42147839e-07])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd_momentum(W, dW, lr, V, beta):\n",
        "    V = beta * V + (1 - beta) * dW\n",
        "    W = W - lr * V\n",
        "    return W, V"
      ],
      "metadata": {
        "id": "fHIV864P5Y50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_p2(optimizer, lr, beta, epochs):\n",
        "    # initial\n",
        "    W = np.array([-5, -2], dtype=np.float32)\n",
        "    V = np.array([0, 0], dtype=np.float32)\n",
        "    results = [W]\n",
        "    for epoch in range(epochs):\n",
        "        dW = df_w(W)\n",
        "        W, V = optimizer(W, dW, lr, V, beta)\n",
        "        results.append(W)\n",
        "    return results"
      ],
      "metadata": {
        "id": "ccaG_bFJ6nBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_p2(sgd_momentum, 0.6, 0.5, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfj2N8398UPi",
        "outputId": "fd1335cc-05bb-41e7-f713-65bed42d24d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([-5., -2.], dtype=float32), array([-4.7,  0.4]), array([-4.268,  1.12 ]), array([-3.79592,  0.136  ]), array([-3.3321248, -0.5192   ]), array([-2.90029971, -0.22376   ]), array([-2.51036919,  0.192472  ]), array([-2.16478177,  0.1696216 ]), array([-1.86210116, -0.04534952]), array([-1.59903478, -0.09841566]), array([-1.37155951, -0.00684994]), array([-1.1755283 ,  0.04715285]), array([-1.006981  ,  0.01757082]), array([-0.86228849, -0.01830518]), array([-0.73820492, -0.01427696]), array([-0.63187084,  0.0048695 ]), array([-0.54079155,  0.00859933]), array([-4.62804416e-01,  1.45050014e-04]), array([-0.39604258, -0.00425615]), array([-0.33889911, -0.00134937]), array([-0.28999343,  0.00172326]), array([-0.24814098,  0.00119166]), array([-0.2123263 , -0.00050413]), array([-0.18167938, -0.00074707]), array([-1.55455157e-01,  2.79448010e-05]), array([-0.13301574,  0.00038192]), array([-1.13815082e-01,  1.00603444e-04]), array([-0.09738585, -0.00016078]), array([-8.33280829e-02, -9.85353344e-05]), array([-7.12995144e-02,  5.08287536e-05]), array([-6.10072592e-02,  6.45162933e-05])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RMSProp(W, dW, lr, S, gamma):\n",
        "    epsilon = 1e-6\n",
        "    S = gamma * S + (1 - gamma) * (dW ** 2)\n",
        "    W = W - lr * dW / (S + epsilon) ** 0.5\n",
        "    return W, S"
      ],
      "metadata": {
        "id": "mvv7j5nS-ICo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_p3(optimizer, lr, gamma, epochs):\n",
        "    # initial\n",
        "    W = np.array([-5, -2], dtype=np.float32)\n",
        "    S = np.array([0, 0], dtype=np.float32)\n",
        "    results = [W]\n",
        "    rs = [np.array([0.2 * W[0], 4 * W[1]])]\n",
        "    for epoch in range(epochs):\n",
        "        dW = df_w(W)\n",
        "        W, S = optimizer(W, dW, lr, S, gamma)\n",
        "        results.append(W)\n",
        "    return results"
      ],
      "metadata": {
        "id": "2MMwaEff_dzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_p3(RMSProp, 0.3, 0.9, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOe4QOxbA0Mu",
        "outputId": "71c7dbd7-51e7-470e-8af4-bbe51960e530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([-5., -2.], dtype=float32), array([-4.05132145, -1.05131678]), array([-3.43519754, -0.59152343]), array([-2.95893693, -0.3294394 ]), array([-2.56546289, -0.17756482]), array([-2.22920552, -0.09163256]), array([-1.93626752, -0.04494499]), array([-1.67817686, -0.02081423]), array([-1.44934985, -0.00903559]), array([-1.24588199, -0.00364591]), array([-1.06490301, -0.00135351]), array([-9.04202260e-01, -4.56444431e-04]), array([-7.61996495e-01, -1.37562928e-04]), array([-6.36778499e-01, -3.62601019e-05]), array([-5.27215237e-01, -8.11337456e-06]), array([-4.32078505e-01, -1.47473412e-06]), array([-3.50198507e-01, -2.02783991e-07]), array([-2.80434649e-01, -1.84231187e-08]), array([-2.21659834e-01, -7.67742748e-10]), array([-1.72755512e-01,  7.80451998e-12]), array([-1.32615134e-01, -5.05794800e-13]), array([-1.00153779e-01,  6.19123501e-14]), array([-7.43217708e-02, -1.13373781e-14]), array([-5.41201278e-02,  2.80166702e-15]), array([-3.86159157e-02, -8.81341191e-16]), array([-2.69558066e-02,  3.39921117e-16]), array([-1.83765633e-02, -1.56581731e-16]), array([-1.22116093e-02,  8.44994985e-17]), array([-7.89331794e-03, -5.26376595e-17]), array([-4.95110261e-03,  3.74107995e-17]), array([-3.00577081e-03, -3.00506084e-17])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Adam(W, dW, lr, V, S, beta1, beta2, t):\n",
        "    epsilon = 1e-6\n",
        "    V = beta1 * V + (1 - beta1) * dW\n",
        "    S = beta1 * S + (1 - beta2) * dW ** 2\n",
        "    V_corr = V / (1 - beta1 ** t)\n",
        "    S_corr = S / (1 - beta2 ** t)\n",
        "    W = W - lr * V_corr / (S_corr ** 0.5 + epsilon)\n",
        "    return W, V, S"
      ],
      "metadata": {
        "id": "c3vcfLSEA-w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_p4(optimizer, lr, beta1, beta2, epochs):\n",
        "    # initial\n",
        "    W = np.array([-5, -2], dtype=np.float32)\n",
        "    V = np.array([0, 0], dtype=np.float32)\n",
        "    S = np.array([0, 0], dtype=np.float32)\n",
        "    results = [W]\n",
        "    for epoch in range(epochs):\n",
        "        t = epoch + 1\n",
        "        dW = df_w(W)\n",
        "        W, V, S = optimizer(W, dW, lr, V, S, beta1, beta2, t)\n",
        "        results.append(W)\n",
        "    return results"
      ],
      "metadata": {
        "id": "JrVCew5uC-yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_p4(Adam, 0.2, 0.9, 0.999, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izo-2XkdEQRL",
        "outputId": "4ede1bd0-1b72-4414-f938-05af4929ec48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([-5., -2.], dtype=float32), array([-4.8000002 , -1.80000002]), array([-4.59489873, -1.59514002]), array([-4.38469996, -1.38570864]), array([-4.16942277, -1.17216029]), array([-3.9491031 , -0.95519395]), array([-3.72379718, -0.7358708 ]), array([-3.49358559, -0.51578574]), array([-3.25857841, -0.2973055 ]), array([-3.01892187, -0.08386568]), array([-2.77480683,  0.11974094]), array([-2.52647979,  0.30727185]), array([-2.27425718,  0.47145159]), array([-2.0185439 ,  0.60513045]), array([-1.75985739,  0.70290276]), array([-1.49885875,  0.76230471]), array([-1.23639265,  0.78389146]), array([-0.97353765,  0.77039113]), array([-0.71166805,  0.72565605]), array([-0.45252637,  0.65391343]), array([-0.198302  ,  0.55941843]), array([0.04829589, 0.44641773]), array([0.2839933 , 0.31931611]), array([0.50496954, 0.18297329]), array([0.70698138, 0.04306955]), array([ 0.88562687, -0.09357454]), array([ 1.03674298, -0.21896482]), array([ 1.15686603, -0.3245306 ]), array([ 1.24362927, -0.40249918]), array([ 1.29597509, -0.44754684]), array([ 1.31413295, -0.4577467 ])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.datasets import FashionMNIST\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKvQAO6RFH_E",
        "outputId": "e3f53267-7c1e-4fac-b121-29e229cfc66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a30dbd23d50>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtqzG_HGL3kh",
        "outputId": "a19cc7a9-50eb-4fbb-8779-48ecbc076edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "num_epochs = 30\n",
        "lr = 0.01"
      ],
      "metadata": {
        "id": "kLcyKVXPFJMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size)"
      ],
      "metadata": {
        "id": "FAjGQk8YFOMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dims, hidden_dims)\n",
        "        self.layer2 = nn.Linear(hidden_dims, hidden_dims)\n",
        "        self.layer3 = nn.Linear(hidden_dims, hidden_dims)\n",
        "        self.layer4 = nn.Linear(hidden_dims, hidden_dims)\n",
        "        self.layer5 = nn.Linear(hidden_dims, hidden_dims)\n",
        "        self.output = nn.Linear(hidden_dims, output_dims)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.Flatten()(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.sigmoid(x)\n",
        "        out = self.output(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AgiFNLdIFWRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_dims=784, hidden_dims=128, output_dims=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "fRfn1eenFccW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "val_losses = []\n",
        "val_acc = []\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    t_loss = 0\n",
        "    t_acc = 0\n",
        "    cnt = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        t_loss += loss.item()\n",
        "        t_acc += (torch.argmax(outputs, 1) == y).sum().item()\n",
        "        cnt += len(y)\n",
        "    t_loss /= len(train_loader)\n",
        "    train_losses.append(t_loss)\n",
        "    t_acc /= cnt\n",
        "    train_acc.append(t_acc)\n",
        "\n",
        "    model.eval()\n",
        "    v_loss = 0\n",
        "    v_acc = 0\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            v_loss += loss.item()\n",
        "            v_acc += (torch.argmax(outputs, 1)==y).sum().item()\n",
        "            cnt += len(y)\n",
        "    v_loss /= len(test_loader)\n",
        "    val_losses.append(v_loss)\n",
        "    v_acc /= cnt\n",
        "    val_acc.append(v_acc)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train_Loss: {t_loss:.4f}, Train_Acc: {t_acc:.4f}, Validation Loss: {v_loss:.4f}, Val_Acc: {v_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I0lI-yDGWiD",
        "outputId": "a67cf729-975b-4261-d7ef-5141aeefb7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train_Loss: 2.3060, Train_Acc: 0.0984, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 2/50, Train_Loss: 2.3028, Train_Acc: 0.0984, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 3/50, Train_Loss: 2.3028, Train_Acc: 0.0972, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 4/50, Train_Loss: 2.3028, Train_Acc: 0.0992, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 5/50, Train_Loss: 2.3028, Train_Acc: 0.0997, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 6/50, Train_Loss: 2.3028, Train_Acc: 0.0979, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 7/50, Train_Loss: 2.3027, Train_Acc: 0.1016, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 8/50, Train_Loss: 2.3028, Train_Acc: 0.0977, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 9/50, Train_Loss: 2.3028, Train_Acc: 0.0987, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 10/50, Train_Loss: 2.3028, Train_Acc: 0.1002, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 11/50, Train_Loss: 2.3028, Train_Acc: 0.0996, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 12/50, Train_Loss: 2.3028, Train_Acc: 0.0984, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 13/50, Train_Loss: 2.3028, Train_Acc: 0.0988, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 14/50, Train_Loss: 2.3029, Train_Acc: 0.0989, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 15/50, Train_Loss: 2.3028, Train_Acc: 0.1013, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 16/50, Train_Loss: 2.3028, Train_Acc: 0.0979, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 17/50, Train_Loss: 2.3028, Train_Acc: 0.0994, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 18/50, Train_Loss: 2.3028, Train_Acc: 0.0988, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 19/50, Train_Loss: 2.3028, Train_Acc: 0.0991, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 20/50, Train_Loss: 2.3028, Train_Acc: 0.0991, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 21/50, Train_Loss: 2.3028, Train_Acc: 0.0992, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 22/50, Train_Loss: 2.3028, Train_Acc: 0.0993, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 23/50, Train_Loss: 2.3028, Train_Acc: 0.1000, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 24/50, Train_Loss: 2.3028, Train_Acc: 0.0986, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 25/50, Train_Loss: 2.3028, Train_Acc: 0.1006, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 26/50, Train_Loss: 2.3028, Train_Acc: 0.0980, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 27/50, Train_Loss: 2.3028, Train_Acc: 0.0977, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 28/50, Train_Loss: 2.3028, Train_Acc: 0.0980, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 29/50, Train_Loss: 2.3028, Train_Acc: 0.0977, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 30/50, Train_Loss: 2.3028, Train_Acc: 0.0978, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 31/50, Train_Loss: 2.3028, Train_Acc: 0.0964, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 32/50, Train_Loss: 2.3027, Train_Acc: 0.1004, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 33/50, Train_Loss: 2.3028, Train_Acc: 0.1002, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 34/50, Train_Loss: 2.3028, Train_Acc: 0.0988, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 35/50, Train_Loss: 2.3028, Train_Acc: 0.0990, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 36/50, Train_Loss: 2.3028, Train_Acc: 0.1002, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 37/50, Train_Loss: 2.3028, Train_Acc: 0.0995, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 38/50, Train_Loss: 2.3028, Train_Acc: 0.0991, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 39/50, Train_Loss: 2.3028, Train_Acc: 0.1003, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 40/50, Train_Loss: 2.3028, Train_Acc: 0.0989, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 41/50, Train_Loss: 2.3028, Train_Acc: 0.0978, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 42/50, Train_Loss: 2.3028, Train_Acc: 0.1006, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 43/50, Train_Loss: 2.3028, Train_Acc: 0.0988, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 44/50, Train_Loss: 2.3028, Train_Acc: 0.0985, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 45/50, Train_Loss: 2.3028, Train_Acc: 0.0964, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 46/50, Train_Loss: 2.3028, Train_Acc: 0.0969, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 47/50, Train_Loss: 2.3028, Train_Acc: 0.0980, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 48/50, Train_Loss: 2.3028, Train_Acc: 0.0988, Validation Loss: 2.3027, Val_Acc: 0.1000\n",
            "Epoch 49/50, Train_Loss: 2.3028, Train_Acc: 0.0996, Validation Loss: 2.3026, Val_Acc: 0.1000\n",
            "Epoch 50/50, Train_Loss: 2.3028, Train_Acc: 0.0978, Validation Loss: 2.3026, Val_Acc: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_dims=784, hidden_dims=128, output_dims=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "_HWu8zIcMaEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "val_losses = []\n",
        "val_acc = []\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    t_loss = 0\n",
        "    t_acc = 0\n",
        "    cnt = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        t_loss += loss.item()\n",
        "        t_acc += (torch.argmax(outputs, 1) == y).sum().item()\n",
        "        cnt += len(y)\n",
        "    t_loss /= len(train_loader)\n",
        "    train_losses.append(t_loss)\n",
        "    t_acc /= cnt\n",
        "    train_acc.append(t_acc)\n",
        "\n",
        "    model.eval()\n",
        "    v_loss = 0\n",
        "    v_acc = 0\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            v_loss += loss.item()\n",
        "            v_acc += (torch.argmax(outputs, 1)==y).sum().item()\n",
        "            cnt += len(y)\n",
        "    v_loss /= len(test_loader)\n",
        "    val_losses.append(v_loss)\n",
        "    v_acc /= cnt\n",
        "    val_acc.append(v_acc)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train_Loss: {t_loss:.4f}, Train_Acc: {t_acc:.4f}, Validation Loss: {v_loss:.4f}, Val_Acc: {v_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkocbT6PNnKQ",
        "outputId": "add392b2-8a02-4b47-dc47-485cd262a2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train_Loss: 2.3055, Train_Acc: 0.1000, Validation Loss: 2.3042, Val_Acc: 0.1000\n",
            "Epoch 2/50, Train_Loss: 2.3041, Train_Acc: 0.0993, Validation Loss: 2.3044, Val_Acc: 0.1000\n",
            "Epoch 3/50, Train_Loss: 2.3041, Train_Acc: 0.0987, Validation Loss: 2.3040, Val_Acc: 0.1000\n",
            "Epoch 4/50, Train_Loss: 2.3043, Train_Acc: 0.0988, Validation Loss: 2.3047, Val_Acc: 0.1000\n",
            "Epoch 5/50, Train_Loss: 2.3042, Train_Acc: 0.1001, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 6/50, Train_Loss: 2.3040, Train_Acc: 0.0977, Validation Loss: 2.3053, Val_Acc: 0.1000\n",
            "Epoch 7/50, Train_Loss: 2.3039, Train_Acc: 0.1002, Validation Loss: 2.3055, Val_Acc: 0.1000\n",
            "Epoch 8/50, Train_Loss: 2.3043, Train_Acc: 0.0994, Validation Loss: 2.3048, Val_Acc: 0.1000\n",
            "Epoch 9/50, Train_Loss: 2.3041, Train_Acc: 0.0993, Validation Loss: 2.3047, Val_Acc: 0.1000\n",
            "Epoch 10/50, Train_Loss: 2.3044, Train_Acc: 0.0999, Validation Loss: 2.3034, Val_Acc: 0.1000\n",
            "Epoch 11/50, Train_Loss: 2.3045, Train_Acc: 0.0992, Validation Loss: 2.3039, Val_Acc: 0.1000\n",
            "Epoch 12/50, Train_Loss: 2.3041, Train_Acc: 0.0978, Validation Loss: 2.3033, Val_Acc: 0.1000\n",
            "Epoch 13/50, Train_Loss: 2.3045, Train_Acc: 0.0994, Validation Loss: 2.3037, Val_Acc: 0.1000\n",
            "Epoch 14/50, Train_Loss: 2.3040, Train_Acc: 0.0991, Validation Loss: 2.3045, Val_Acc: 0.1000\n",
            "Epoch 15/50, Train_Loss: 2.3041, Train_Acc: 0.0996, Validation Loss: 2.3041, Val_Acc: 0.1000\n",
            "Epoch 16/50, Train_Loss: 2.3040, Train_Acc: 0.1011, Validation Loss: 2.3035, Val_Acc: 0.1000\n",
            "Epoch 17/50, Train_Loss: 2.3046, Train_Acc: 0.0994, Validation Loss: 2.3034, Val_Acc: 0.1000\n",
            "Epoch 18/50, Train_Loss: 2.3043, Train_Acc: 0.1006, Validation Loss: 2.3030, Val_Acc: 0.1000\n",
            "Epoch 19/50, Train_Loss: 2.3046, Train_Acc: 0.1009, Validation Loss: 2.3042, Val_Acc: 0.1000\n",
            "Epoch 20/50, Train_Loss: 2.3040, Train_Acc: 0.0985, Validation Loss: 2.3048, Val_Acc: 0.1000\n",
            "Epoch 21/50, Train_Loss: 2.3042, Train_Acc: 0.1002, Validation Loss: 2.3037, Val_Acc: 0.1000\n",
            "Epoch 22/50, Train_Loss: 2.3040, Train_Acc: 0.0973, Validation Loss: 2.3038, Val_Acc: 0.1000\n",
            "Epoch 23/50, Train_Loss: 2.3044, Train_Acc: 0.0989, Validation Loss: 2.3042, Val_Acc: 0.1000\n",
            "Epoch 24/50, Train_Loss: 2.3039, Train_Acc: 0.0987, Validation Loss: 2.3052, Val_Acc: 0.1000\n",
            "Epoch 25/50, Train_Loss: 2.3042, Train_Acc: 0.1002, Validation Loss: 2.3048, Val_Acc: 0.1000\n",
            "Epoch 26/50, Train_Loss: 2.3041, Train_Acc: 0.1012, Validation Loss: 2.3043, Val_Acc: 0.1000\n",
            "Epoch 27/50, Train_Loss: 2.3041, Train_Acc: 0.0987, Validation Loss: 2.3039, Val_Acc: 0.1000\n",
            "Epoch 28/50, Train_Loss: 2.3044, Train_Acc: 0.0978, Validation Loss: 2.3042, Val_Acc: 0.1000\n",
            "Epoch 29/50, Train_Loss: 2.3040, Train_Acc: 0.1003, Validation Loss: 2.3052, Val_Acc: 0.1000\n",
            "Epoch 30/50, Train_Loss: 2.3042, Train_Acc: 0.0974, Validation Loss: 2.3033, Val_Acc: 0.1000\n",
            "Epoch 31/50, Train_Loss: 2.3041, Train_Acc: 0.0986, Validation Loss: 2.3043, Val_Acc: 0.1000\n",
            "Epoch 32/50, Train_Loss: 2.3040, Train_Acc: 0.0992, Validation Loss: 2.3037, Val_Acc: 0.1000\n",
            "Epoch 33/50, Train_Loss: 2.3040, Train_Acc: 0.0993, Validation Loss: 2.3042, Val_Acc: 0.1000\n",
            "Epoch 34/50, Train_Loss: 2.3036, Train_Acc: 0.0991, Validation Loss: 2.3042, Val_Acc: 0.1000\n",
            "Epoch 35/50, Train_Loss: 2.3045, Train_Acc: 0.0982, Validation Loss: 2.3034, Val_Acc: 0.1000\n",
            "Epoch 36/50, Train_Loss: 2.3044, Train_Acc: 0.0979, Validation Loss: 2.3041, Val_Acc: 0.1000\n",
            "Epoch 37/50, Train_Loss: 2.3042, Train_Acc: 0.0974, Validation Loss: 2.3040, Val_Acc: 0.1000\n",
            "Epoch 38/50, Train_Loss: 2.3039, Train_Acc: 0.0988, Validation Loss: 2.3046, Val_Acc: 0.1000\n",
            "Epoch 39/50, Train_Loss: 2.3042, Train_Acc: 0.0995, Validation Loss: 2.3038, Val_Acc: 0.1000\n",
            "Epoch 40/50, Train_Loss: 2.3042, Train_Acc: 0.1005, Validation Loss: 2.3041, Val_Acc: 0.1000\n",
            "Epoch 41/50, Train_Loss: 2.3040, Train_Acc: 0.0974, Validation Loss: 2.3041, Val_Acc: 0.1000\n",
            "Epoch 42/50, Train_Loss: 2.3044, Train_Acc: 0.0982, Validation Loss: 2.3032, Val_Acc: 0.1000\n",
            "Epoch 43/50, Train_Loss: 2.3037, Train_Acc: 0.0987, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 44/50, Train_Loss: 2.3038, Train_Acc: 0.0997, Validation Loss: 2.3031, Val_Acc: 0.1000\n",
            "Epoch 45/50, Train_Loss: 2.3038, Train_Acc: 0.0996, Validation Loss: 2.3030, Val_Acc: 0.1000\n",
            "Epoch 46/50, Train_Loss: 2.3040, Train_Acc: 0.0993, Validation Loss: 2.3039, Val_Acc: 0.1000\n",
            "Epoch 47/50, Train_Loss: 2.3038, Train_Acc: 0.0987, Validation Loss: 2.3034, Val_Acc: 0.1000\n",
            "Epoch 48/50, Train_Loss: 2.3039, Train_Acc: 0.0999, Validation Loss: 2.3043, Val_Acc: 0.1000\n",
            "Epoch 49/50, Train_Loss: 2.3042, Train_Acc: 0.0994, Validation Loss: 2.3028, Val_Acc: 0.1000\n",
            "Epoch 50/50, Train_Loss: 2.3040, Train_Acc: 0.0996, Validation Loss: 2.3034, Val_Acc: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_dims=784, hidden_dims=128, output_dims=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "g6i7XP8nN_Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "val_losses = []\n",
        "val_acc = []\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    t_loss = 0\n",
        "    t_acc = 0\n",
        "    cnt = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        t_loss += loss.item()\n",
        "        t_acc += (torch.argmax(outputs, 1) == y).sum().item()\n",
        "        cnt += len(y)\n",
        "    t_loss /= len(train_loader)\n",
        "    train_losses.append(t_loss)\n",
        "    t_acc /= cnt\n",
        "    train_acc.append(t_acc)\n",
        "\n",
        "    model.eval()\n",
        "    v_loss = 0\n",
        "    v_acc = 0\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            v_loss += loss.item()\n",
        "            v_acc += (torch.argmax(outputs, 1)==y).sum().item()\n",
        "            cnt += len(y)\n",
        "    v_loss /= len(test_loader)\n",
        "    val_losses.append(v_loss)\n",
        "    v_acc /= cnt\n",
        "    val_acc.append(v_acc)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train_Loss: {t_loss:.4f}, Train_Acc: {t_acc:.4f}, Validation Loss: {v_loss:.4f}, Val_Acc: {v_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHOKG2chOf5w",
        "outputId": "af91f9f6-d074-43d0-8a50-014b826d31b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Train_Loss: 2.3042, Train_Acc: 0.0992, Validation Loss: 2.3035, Val_Acc: 0.1000\n",
            "Epoch 2/30, Train_Loss: 2.2436, Train_Acc: 0.1183, Validation Loss: 1.7508, Val_Acc: 0.1998\n",
            "Epoch 3/30, Train_Loss: 1.6408, Train_Acc: 0.2339, Validation Loss: 1.5672, Val_Acc: 0.2746\n",
            "Epoch 4/30, Train_Loss: 1.2407, Train_Acc: 0.4092, Validation Loss: 1.0970, Val_Acc: 0.4745\n",
            "Epoch 5/30, Train_Loss: 0.9904, Train_Acc: 0.5300, Validation Loss: 0.9527, Val_Acc: 0.5464\n",
            "Epoch 6/30, Train_Loss: 0.8406, Train_Acc: 0.6313, Validation Loss: 0.9307, Val_Acc: 0.6083\n",
            "Epoch 7/30, Train_Loss: 0.6445, Train_Acc: 0.7537, Validation Loss: 0.7084, Val_Acc: 0.7431\n",
            "Epoch 8/30, Train_Loss: 0.5563, Train_Acc: 0.7907, Validation Loss: 0.7368, Val_Acc: 0.7234\n",
            "Epoch 9/30, Train_Loss: 0.5192, Train_Acc: 0.8057, Validation Loss: 0.6699, Val_Acc: 0.7478\n",
            "Epoch 10/30, Train_Loss: 0.4795, Train_Acc: 0.8286, Validation Loss: 0.5927, Val_Acc: 0.7897\n",
            "Epoch 11/30, Train_Loss: 0.4338, Train_Acc: 0.8464, Validation Loss: 0.5528, Val_Acc: 0.7870\n",
            "Epoch 12/30, Train_Loss: 0.4141, Train_Acc: 0.8519, Validation Loss: 0.6130, Val_Acc: 0.7732\n",
            "Epoch 13/30, Train_Loss: 0.3966, Train_Acc: 0.8589, Validation Loss: 0.5424, Val_Acc: 0.8151\n",
            "Epoch 14/30, Train_Loss: 0.3931, Train_Acc: 0.8594, Validation Loss: 0.5498, Val_Acc: 0.8121\n",
            "Epoch 15/30, Train_Loss: 0.3758, Train_Acc: 0.8637, Validation Loss: 0.4194, Val_Acc: 0.8516\n",
            "Epoch 16/30, Train_Loss: 0.3624, Train_Acc: 0.8702, Validation Loss: 0.4737, Val_Acc: 0.8267\n",
            "Epoch 17/30, Train_Loss: 0.3547, Train_Acc: 0.8730, Validation Loss: 0.4234, Val_Acc: 0.8485\n",
            "Epoch 18/30, Train_Loss: 0.3443, Train_Acc: 0.8756, Validation Loss: 0.5261, Val_Acc: 0.8103\n",
            "Epoch 19/30, Train_Loss: 0.3395, Train_Acc: 0.8763, Validation Loss: 0.5304, Val_Acc: 0.8051\n",
            "Epoch 20/30, Train_Loss: 0.3275, Train_Acc: 0.8812, Validation Loss: 0.4450, Val_Acc: 0.8435\n",
            "Epoch 21/30, Train_Loss: 0.3273, Train_Acc: 0.8790, Validation Loss: 0.4546, Val_Acc: 0.8480\n",
            "Epoch 22/30, Train_Loss: 0.3203, Train_Acc: 0.8824, Validation Loss: 0.5402, Val_Acc: 0.8134\n",
            "Epoch 23/30, Train_Loss: 0.3163, Train_Acc: 0.8827, Validation Loss: 0.4467, Val_Acc: 0.8400\n",
            "Epoch 24/30, Train_Loss: 0.3039, Train_Acc: 0.8879, Validation Loss: 0.4019, Val_Acc: 0.8526\n",
            "Epoch 25/30, Train_Loss: 0.3016, Train_Acc: 0.8881, Validation Loss: 0.4295, Val_Acc: 0.8525\n",
            "Epoch 26/30, Train_Loss: 0.3031, Train_Acc: 0.8888, Validation Loss: 0.3861, Val_Acc: 0.8663\n",
            "Epoch 27/30, Train_Loss: 0.2949, Train_Acc: 0.8912, Validation Loss: 0.4300, Val_Acc: 0.8569\n",
            "Epoch 28/30, Train_Loss: 0.2895, Train_Acc: 0.8928, Validation Loss: 0.4852, Val_Acc: 0.8362\n",
            "Epoch 29/30, Train_Loss: 0.2891, Train_Acc: 0.8943, Validation Loss: 0.4271, Val_Acc: 0.8464\n",
            "Epoch 30/30, Train_Loss: 0.2844, Train_Acc: 0.8944, Validation Loss: 0.4236, Val_Acc: 0.8554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_dims=784, hidden_dims=128, output_dims=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "5JpYGv1SPjp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_acc = []\n",
        "val_losses = []\n",
        "val_acc = []\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    t_loss = 0\n",
        "    t_acc = 0\n",
        "    cnt = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        t_loss += loss.item()\n",
        "        t_acc += (torch.argmax(outputs, 1) == y).sum().item()\n",
        "        cnt += len(y)\n",
        "    t_loss /= len(train_loader)\n",
        "    train_losses.append(t_loss)\n",
        "    t_acc /= cnt\n",
        "    train_acc.append(t_acc)\n",
        "\n",
        "    model.eval()\n",
        "    v_loss = 0\n",
        "    v_acc = 0\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            v_loss += loss.item()\n",
        "            v_acc += (torch.argmax(outputs, 1)==y).sum().item()\n",
        "            cnt += len(y)\n",
        "    v_loss /= len(test_loader)\n",
        "    val_losses.append(v_loss)\n",
        "    v_acc /= cnt\n",
        "    val_acc.append(v_acc)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train_Loss: {t_loss:.4f}, Train_Acc: {t_acc:.4f}, Validation Loss: {v_loss:.4f}, Val_Acc: {v_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzwBtqtNPhhF",
        "outputId": "1d0fb4a2-f920-4554-a4bd-3e4099091805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Train_Loss: 1.6530, Train_Acc: 0.2641, Validation Loss: 1.1066, Val_Acc: 0.4796\n",
            "Epoch 2/30, Train_Loss: 0.8540, Train_Acc: 0.6345, Validation Loss: 0.7311, Val_Acc: 0.7140\n",
            "Epoch 3/30, Train_Loss: 0.6721, Train_Acc: 0.7316, Validation Loss: 0.6540, Val_Acc: 0.7481\n",
            "Epoch 4/30, Train_Loss: 0.5730, Train_Acc: 0.7863, Validation Loss: 0.5864, Val_Acc: 0.7837\n",
            "Epoch 5/30, Train_Loss: 0.4484, Train_Acc: 0.8453, Validation Loss: 0.4543, Val_Acc: 0.8429\n",
            "Epoch 6/30, Train_Loss: 0.4000, Train_Acc: 0.8622, Validation Loss: 0.4420, Val_Acc: 0.8478\n",
            "Epoch 7/30, Train_Loss: 0.3741, Train_Acc: 0.8704, Validation Loss: 0.4315, Val_Acc: 0.8458\n",
            "Epoch 8/30, Train_Loss: 0.3611, Train_Acc: 0.8747, Validation Loss: 0.4485, Val_Acc: 0.8433\n",
            "Epoch 9/30, Train_Loss: 0.3461, Train_Acc: 0.8790, Validation Loss: 0.4127, Val_Acc: 0.8586\n",
            "Epoch 10/30, Train_Loss: 0.3274, Train_Acc: 0.8834, Validation Loss: 0.4050, Val_Acc: 0.8608\n",
            "Epoch 11/30, Train_Loss: 0.3185, Train_Acc: 0.8868, Validation Loss: 0.3840, Val_Acc: 0.8700\n",
            "Epoch 12/30, Train_Loss: 0.3080, Train_Acc: 0.8892, Validation Loss: 0.3687, Val_Acc: 0.8698\n",
            "Epoch 13/30, Train_Loss: 0.3051, Train_Acc: 0.8907, Validation Loss: 0.3759, Val_Acc: 0.8658\n",
            "Epoch 14/30, Train_Loss: 0.2939, Train_Acc: 0.8946, Validation Loss: 0.3768, Val_Acc: 0.8673\n",
            "Epoch 15/30, Train_Loss: 0.2862, Train_Acc: 0.8955, Validation Loss: 0.3814, Val_Acc: 0.8687\n",
            "Epoch 16/30, Train_Loss: 0.2814, Train_Acc: 0.8978, Validation Loss: 0.3667, Val_Acc: 0.8715\n",
            "Epoch 17/30, Train_Loss: 0.2793, Train_Acc: 0.8983, Validation Loss: 0.3818, Val_Acc: 0.8604\n",
            "Epoch 18/30, Train_Loss: 0.2757, Train_Acc: 0.8999, Validation Loss: 0.3872, Val_Acc: 0.8646\n",
            "Epoch 19/30, Train_Loss: 0.2689, Train_Acc: 0.9016, Validation Loss: 0.3744, Val_Acc: 0.8726\n",
            "Epoch 20/30, Train_Loss: 0.2590, Train_Acc: 0.9038, Validation Loss: 0.4137, Val_Acc: 0.8635\n",
            "Epoch 21/30, Train_Loss: 0.2614, Train_Acc: 0.9031, Validation Loss: 0.3756, Val_Acc: 0.8727\n",
            "Epoch 22/30, Train_Loss: 0.2553, Train_Acc: 0.9067, Validation Loss: 0.3691, Val_Acc: 0.8740\n",
            "Epoch 23/30, Train_Loss: 0.2430, Train_Acc: 0.9107, Validation Loss: 0.3621, Val_Acc: 0.8760\n",
            "Epoch 24/30, Train_Loss: 0.2417, Train_Acc: 0.9100, Validation Loss: 0.3528, Val_Acc: 0.8749\n",
            "Epoch 25/30, Train_Loss: 0.2355, Train_Acc: 0.9137, Validation Loss: 0.3562, Val_Acc: 0.8770\n",
            "Epoch 26/30, Train_Loss: 0.2326, Train_Acc: 0.9136, Validation Loss: 0.3737, Val_Acc: 0.8760\n",
            "Epoch 27/30, Train_Loss: 0.2376, Train_Acc: 0.9130, Validation Loss: 0.3684, Val_Acc: 0.8794\n",
            "Epoch 28/30, Train_Loss: 0.2319, Train_Acc: 0.9156, Validation Loss: 0.3570, Val_Acc: 0.8790\n",
            "Epoch 29/30, Train_Loss: 0.2292, Train_Acc: 0.9153, Validation Loss: 0.3866, Val_Acc: 0.8766\n",
            "Epoch 30/30, Train_Loss: 0.2315, Train_Acc: 0.9153, Validation Loss: 0.3663, Val_Acc: 0.8744\n"
          ]
        }
      ]
    }
  ]
}